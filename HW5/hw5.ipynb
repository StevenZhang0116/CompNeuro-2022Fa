{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code serves for the 5th homework in Computational Neuroscicence taught by Xiao-Jing Wang in Fall 2022 semester. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate N-dimensional input data with zero mean and some set covariance\n",
    "def n_covariance(N,eta,K):\n",
    "    # create A N*N matrix where each entry is drawn independently from a Gaussian distribution\n",
    "    A = np.random.normal(0,np.sqrt(eta**2/N),size=(N,N))\n",
    "    # covariance matrix\n",
    "    Sigma = np.matmul(A,A.T)\n",
    "    # epsilon, generate from N(0,1), generate K samples, K large\n",
    "    xxset = np.zeros(shape=(K,N))\n",
    "    for i in range(K):\n",
    "        epsi = np.random.normal(0,1,size=(N,1))\n",
    "        xx = np.matmul(A,epsi)\n",
    "        xxset[i] = xx.T\n",
    "        \n",
    "    return [A,Sigma,xxset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem 1\n",
    "np.random.seed()\n",
    "\n",
    "N = 10\n",
    "eta = 1\n",
    "K = 100 # how many data points\n",
    "[A,Sigma,xx] = n_covariance(N,eta,K)\n",
    "\n",
    "# Compute eigenvalues and eigenvectors\n",
    "# Sigma = np.cov(xx.T)\n",
    "[eigu,eigv] = np.linalg.eig(Sigma)\n",
    "\n",
    "# largest eigenvalue\n",
    "ind = np.argmax(eigu)\n",
    "# corresponding eigenvector\n",
    "lag_eigv = eigv[:,ind]\n",
    "\n",
    "# print(f\"eigenvalue:{eigu}\")\n",
    "# print(f\"eigenvector:{eigv}\")\n",
    "\n",
    "# Initialize the weights at random from zero mean unit variance gaussian\n",
    "W_oja = np.random.normal(0,1,size=(N,1))\n",
    "prev_W_oja = np.ones((N,1))\n",
    "\n",
    "learn_rate = 0.001\n",
    "train_iteration = 1000\n",
    "W_oja_norm = [] # norm\n",
    "W_oja_set = [] # store\n",
    "cnt = 0 # iterator\n",
    "\n",
    "a1 = max(xx[:,0])/lag_eigv[0]\n",
    "a2 = min(xx[:,0])/lag_eigv[0]\n",
    "\n",
    "for i in range(train_iteration):\n",
    "    Ys = np.dot(xx,W_oja)\n",
    "    W_oja += learn_rate * np.sum(Ys*xx-np.square(Ys)*W_oja.T,axis=0).reshape((N,1))\n",
    "    W_oja_norm.append(np.linalg.norm(W_oja))\n",
    "    W_oja_set.append(W_oja.tolist())\n",
    "    cnt += 1\n",
    "\n",
    "    if cnt % 20 == 0 and cnt < 200:\n",
    "        plt.figure(figsize=(5,5))\n",
    "        plt.scatter(xx[:,0],xx[:,1],color='y',label='data pts')\n",
    "        plt.plot([a1*lag_eigv[0],a2*lag_eigv[0]],[a1*lag_eigv[1],a2*lag_eigv[1]],color='r',label='PC1')\n",
    "        plt.scatter(W_oja[0],W_oja[1],color='b',label='proj1')\n",
    "        plt.title(f\"Result when iteration={cnt}\")\n",
    "\n",
    "W_oja_set = np.array(W_oja_set)\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.scatter(xx[:,0],xx[:,1],color='y',label='data pts')\n",
    "plt.plot([a1*lag_eigv[0],a2*lag_eigv[0]],[a1*lag_eigv[1],a2*lag_eigv[1]],color='r',label='PC1')\n",
    "plt.scatter(W_oja[0],W_oja[1],color='b',label='proj1')\n",
    "plt.title(f\"Result when iteration={cnt}\")\n",
    "\n",
    "plt.legend()\n",
    "plt.title(f'Result when iteration={cnt}')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Required iteration:{cnt}\")\n",
    "print(f\"W_oja after train:{W_oja}\")\n",
    "print(f\"large eigenvector:{lag_eigv}\")\n",
    "\n",
    "plt.figure(figsize=(5,5)) \n",
    "plt.plot(W_oja_norm)\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Norm')\n",
    "\n",
    "if lag_eigv[0] * W_oja[0] <= 0:\n",
    "    lag_eigv = -1 * lag_eigv\n",
    "    \n",
    "plt.figure(figsize=(5,5))\n",
    "plt.scatter(W_oja_set[:,0],W_oja_set[:,1],label='trajectory of weights')\n",
    "plt.scatter(lag_eigv[0],lag_eigv[1],label='First PC weight')\n",
    "plt.xlabel('Weight 1')\n",
    "plt.ylabel('Weight 2')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "time.sleep(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Problem 2\n",
    "A_plus = 1.03\n",
    "A_minus = -0.51\n",
    "tau_plus = 14 # ms\n",
    "tau_minus = 34 # ms\n",
    "pre_freq = 10 / 10**3 # cycle/ms (10^3 times original Hz)\n",
    "post_freq_range = np.linspace(0,25,50) / 10**3\n",
    "\n",
    "# generate poisson process\n",
    "def poisson_process(rate,tmax,bin_size):\n",
    "    nbins = np.floor(tmax/bin_size).astype(int)\n",
    "    prob_of_spike = rate * bin_size\n",
    "    spikes = np.random.rand(nbins) < prob_of_spike\n",
    "    return spikes * 1\n",
    "    \n",
    "def closest_neighbor(spike_f,spike_s):\n",
    "    indx_f = np.where(spike_f == 1)[0]\n",
    "    indx_s = np.where(spike_s == 1)[0]\n",
    "    be_af_set = [] # length equal to number of presynaptic spike in duration\n",
    "    for i in indx_f:\n",
    "        try:\n",
    "            largest_small = max(j for j in indx_s if j < i)\n",
    "        except ValueError:\n",
    "            largest_small = 1e30\n",
    "        try:\n",
    "            smallest_large = min(j for j in indx_s if j > i)\n",
    "        except ValueError:\n",
    "            smallest_large = 1e30\n",
    "\n",
    "        temp_set = [largest_small,smallest_large]\n",
    "        be_af_set.append(temp_set)\n",
    "    return [indx_f,indx_s,be_af_set]\n",
    "\n",
    "bin_size = 0.01 # ms\n",
    "sim_time = 10000 # ms\n",
    "repeat = 1000 # independent trails\n",
    "actual_mean = []\n",
    "\n",
    "for kkkk in range(len(post_freq_range)):\n",
    "    across_trail = []\n",
    "    for j in range(repeat):\n",
    "        post_freq = post_freq_range[kkkk]\n",
    "        pre_spikes_poisson = poisson_process(pre_freq,sim_time,bin_size)\n",
    "        # print(f\"number of presynaptic spikes: {sum(pre_spikes_poisson)}\")\n",
    "        post_spikes_poisson = poisson_process(post_freq,sim_time,bin_size)\n",
    "        tt = np.arange(len(post_spikes_poisson)) * bin_size # time\n",
    "\n",
    "        [indx_f,indx_s,be_af_set] = closest_neighbor(pre_spikes_poisson,post_spikes_poisson)\n",
    "        deltaW_set = []\n",
    "\n",
    "        for i in range(len(indx_f)):\n",
    "            pretime = indx_f[i] * bin_size\n",
    "            posttime_f = be_af_set[i][0] * bin_size\n",
    "            posttime_s = be_af_set[i][1] * bin_size\n",
    "            \n",
    "            deltaW_f = 0\n",
    "            deltaW_s = 0\n",
    "            deltaW = 0\n",
    "            # first postsynaptic event (before presynaptic)\n",
    "            # t_post < t_pre\n",
    "            if posttime_f < 1e8:\n",
    "                deltaW_f = A_minus*np.exp(-(pretime-posttime_f)/tau_minus)\n",
    "            # second postsynaptic event (before presynaptic)\n",
    "            # t_post > t_pre\n",
    "            if posttime_s < 1e8:\n",
    "                deltaW_s = A_plus*np.exp((pretime-posttime_s)/tau_plus)\n",
    "            deltaW += (deltaW_f + deltaW_s)\n",
    "            deltaW_set.append(deltaW)\n",
    "        # average across every synaptic event\n",
    "        mean_deltaW = np.mean(deltaW_set)\n",
    "        across_trail.append(mean_deltaW)\n",
    "        # print(mean_deltaW)\n",
    "    # average across different independent trails\n",
    "    across_trail_mean = np.mean(across_trail)\n",
    "    actual_mean.append(across_trail_mean)\n",
    "    # print(across_trail_mean)\n",
    "\n",
    "actual_mean = np.array(actual_mean)\n",
    "\n",
    "stand_curve = []\n",
    "for x in post_freq_range:\n",
    "    stand_curve.append(x*(A_plus/(tau_plus**(-1)+x)+A_minus/(tau_minus**(-1)+x)))\n",
    "stand_curve = np.array(stand_curve)\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.scatter(post_freq_range*1000,actual_mean*100,color='r',label='experimental results')\n",
    "plt.plot(post_freq_range*1000,stand_curve*100,color='g',label='standard curve')\n",
    "plt.xlabel('Postsynaptic firing rate x, Hz')\n",
    "plt.ylabel('Synaptic Change, %')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
